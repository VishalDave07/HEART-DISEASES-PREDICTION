{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Predicting Heart Disease with Classification Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imorting files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"A:\\Softwares\\Projects\\Heart Disease\\Heart_disease_data.csv\"\n",
    "\n",
    "data = pd.read_csv(filePath)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Rows, columns): \" + str(data.shape))\n",
    "data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique(axis=0)# returns the number of unique values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarizes the count, mean, standard deviation, min, and max for numeric variables.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Missing Values\n",
    "\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "\n",
    "corr = data.corr()\n",
    "plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n",
    "sns.heatmap(corr, xticklabels=corr.columns,\n",
    "            yticklabels=corr.columns, \n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(220, 20, as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subData = data[['age','trestbps','chol','thalach','oldpeak']]\n",
    "sns.pairplot(subData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"target\", y=\"oldpeak\", hue=\"slope\", kind=\"bar\", data=data);\n",
    "\n",
    "plt.title('ST depression (induced by exercise relative to rest) vs. Heart Disease',size=25)\n",
    "plt.xlabel('Heart Disease',size=20)\n",
    "plt.ylabel('ST depression',size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Violin &  Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.violinplot(x= 'target', y= 'oldpeak',hue=\"sex\", inner='quartile',data= data )\n",
    "plt.title(\"Thalach Level vs. Heart Disease\",fontsize=20)\n",
    "plt.xlabel(\"Heart Disease Target\", fontsize=16)\n",
    "plt.ylabel(\"Thalach Level\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x= 'target', y= 'thalach',hue=\"sex\", data=data )\n",
    "plt.title(\"ST depression Level vs. Heart Disease\", fontsize=20)\n",
    "plt.xlabel(\"Heart Disease Target\",fontsize=16)\n",
    "plt.ylabel(\"ST depression induced by exercise relative to rest\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Filtering data by positive & negative Heart Disease patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data by positive Heart Disease patient \n",
    "pos_data = data[data['target']==1]\n",
    "pos_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data by negative Heart Disease patient \n",
    "neg_data = data[data['target']==0]\n",
    "neg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Positive Patients ST depression): \" + str(pos_data['oldpeak'].mean()))\n",
    "print(\"(Negative Patients ST depression): \" + str(neg_data['oldpeak'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Positive Patients thalach): \" + str(pos_data['thalach'].mean()))\n",
    "print(\"(Negative Patients thalach): \" + str(neg_data['thalach'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine Learning + Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split: the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling /Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = LogisticRegression(random_state=1) # get instance of model\n",
    "model1.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred1 = model1.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred1)) # output accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: K-NN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model2 = KNeighborsClassifier() # get instance of model\n",
    "model2.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred2 = model2.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred2)) # output accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model3 = SVC(random_state=1) # get instance of model\n",
    "model3.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred3 = model3.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred3)) # output accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4:  Naives Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model4 = GaussianNB() # get instance of model\n",
    "model4.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred4 = model4.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred4)) # output accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5: Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model5 = DecisionTreeClassifier(random_state=1) # get instance of model\n",
    "model5.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred5 = model5.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred5)) # output accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6: Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model6 = RandomForestClassifier(random_state=1)# get instance of model\n",
    "model6.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred6 = model6.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred6)) # output accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 7:  XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model7 = XGBClassifier(random_state=1)\n",
    "model7.fit(x_train, y_train)\n",
    "y_pred7 = model7.predict(x_test)\n",
    "print(classification_report(y_test, y_pred7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred6)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importance = model6.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index= data.columns[:-1]\n",
    "importance = pd.Series(model6.feature_importances_, index=index)\n",
    "importance.nlargest(13).plot(kind='barh', colormap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model6.predict(sc.transform([[20,1,2,110,230,1,1,140,1,2.2,2,0,2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model6.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
